{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb92a0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as t\n",
    "from torch.utils.data.dataloader import DataLoader as dl\n",
    "from torch.utils.data import TensorDataset, Dataset, Subset\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor as rfr\n",
    "from sklearn.linear_model import BayesianRidge as bayR\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor as gradB\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler as ss\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_squared_log_error as mslr\n",
    "from joblib import parallel_backend # to improve sklearn training speed\n",
    "import os\n",
    "import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "from sklearn.decomposition import PCA\n",
    "import optuna as opt\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "import pickle\n",
    "\n",
    "from scipy import stats\n",
    "from scipy import optimize as sciOpt\n",
    "\n",
    "from pymoo.algorithms.nsga2 import NSGA2\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.model.problem import FunctionalProblem\n",
    "from pymoo.factory import get_termination\n",
    "from pymoo.visualization.scatter import Scatter\n",
    "\n",
    "from pymoo.util.display import Display\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25776a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes and Functions\n",
    "\n",
    "\n",
    "class MyDisplay(Display):\n",
    "    \n",
    "    def _do(self, problem, evaluator, algorithm):\n",
    "        super()._do(problem, evaluator, algorithm)\n",
    "        self.output.append(\"X\", np.mean(algorithm.pop.get(\"X\")))\n",
    "        self.output.append(\"F\", np.mean(algorithm.pop.get(\"F\")))\n",
    "\n",
    "\n",
    "class LitModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, x, trial=None):\n",
    "        super().__init__()\n",
    "        if trial is not None:\n",
    "            self.lr = trial.suggest_float(\"lr\", minLr, maxLr)\n",
    "            self.weight_decay =  trial.suggest_float(\"weight_decay\", minWD, maxWD)\n",
    "        else:\n",
    "            self.lr = bestDict[\"lr\"]\n",
    "            self.weight_decay =  bestDict[\"weight_decay\"]\n",
    "        self.model = makeModel(trial, bestDict)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x.view(x.size(0), -1))\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log('train_loss', loss, prog_bar=True,on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "       return t.optim.Adam(self.parameters(), \n",
    "                           lr=(self.lr or self.learning_rate))\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        val_loss =F.mse_loss(y_hat, y)\n",
    "        self.log('val_loss', val_loss, prog_bar=True,on_epoch=True)\n",
    "        return val_loss\n",
    "\n",
    "\n",
    "\n",
    "class net(nn.Module):\n",
    "\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__()\n",
    "        self.xShape = x.shape\n",
    "        self.yShape = y.shape\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(self.xShape[1],128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,1))\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class dset(Dataset):\n",
    "\n",
    "\n",
    "    def __init__(self, xAll,yAll):\n",
    "        super().__init__()\n",
    "        self.xAll = xAll\n",
    "        self.yAll = yAll\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.xAll.shape[0]\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = self.xAll[i]\n",
    "        y = self.xAll[i]\n",
    "        return (t.Tensor(x,dtype=t.float), t.Tensor(y,dtype=t.float))\n",
    "\n",
    "\n",
    "def pickleLoad(filename):\n",
    "    with open(rf'{filename}','rb') as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "def pickleSave(filename, obj):\n",
    "    with open(f'{filename}','wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "\n",
    "def makeModel(trial = None, hpDict = None):\n",
    "    # sets layers and number of neurons for each trial\n",
    "    #builds dict with parameters that can be used to make best model\n",
    "    layers=[]\n",
    "    inFeat = xTrT.shape[1] #assumes 1D data for each sample\n",
    "    lastOut = yTrT.shape[1]\n",
    "    if trial is not None:\n",
    "        nl = trial.suggest_int(\"nL\",minLayers,maxLayers)\n",
    "        \n",
    "        for i in range(nl):\n",
    "            outFeat = trial.suggest_int(f\"n{i}\",minNeurons,maxNeurons)\n",
    "            layers.append(nn.Linear(inFeat, outFeat))\n",
    "            actiLayer = trial.suggest_categorical(f\"a{i}\",possibleActiFuncs)\n",
    "            layers.append(getattr(nn, actiLayer)())\n",
    "            dropOutRatio = trial.suggest_float(f\"dropoutL{i}\",minDropOut,maxDropOut)\n",
    "            layers.append(nn.Dropout(dropOutRatio))\n",
    "            inFeat = outFeat\n",
    "            \n",
    "    elif hpDict is not None:\n",
    "        nl = hpDict[\"nL\"]\n",
    "        \n",
    "        for i in range(nl):\n",
    "            outFeat = hpDict[f\"n{i}\"]\n",
    "            layers.append(nn.Linear(inFeat, outFeat))\n",
    "            actiLayer = hpDict[f\"a{i}\"]\n",
    "            layers.append(getattr(nn, actiLayer)())\n",
    "            dropOutRatio = hpDict[f\"dropoutL{i}\"]\n",
    "            layers.append(nn.Dropout(dropOutRatio))\n",
    "            inFeat = outFeat\n",
    "            \n",
    "    layers.append(nn.Linear(inFeat, lastOut))\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "\n",
    "def runShallowOpt(model, modelname,idxSel):\n",
    "    with parallel_backend('threading', n_jobs=-1):\n",
    "        model.fit(xTrT, yTrT)\n",
    "    yTrPredInvTrans = predictAndInvTransform(xTrT, model)\n",
    "    yEPredInvTrans = predictAndInvTransform(xET, model)\n",
    "\n",
    "    mseLoss = mse(yEPredInvTrans, yE)\n",
    "    rmsleLossTrain = RMSLE(yTrPredInvTrans, yTr)\n",
    "    rmsleLossEval = RMSLE(yEPredInvTrans, yE)\n",
    "\n",
    "    #predSub = predictAndInvTransform(teDT,model)\n",
    "    \n",
    "    print(modelname,f' TrainLoss {rmsleLossTrain:.3f}, evalLoss: {rmsleLossEval:.3f}')\n",
    "    return rmsleLossTrain, rmsleLossEval\n",
    "\n",
    "\n",
    "        \n",
    "def shallowObjective(trial):\n",
    "\n",
    "    modelname = trial.suggest_categorical(\"modelname\",possibleShallows)\n",
    "    idxArr = np.arange(len(xTrT))\n",
    "    np.random.shuffle(idxArr)\n",
    "    if numShallowSamples >= len(xTrT):\n",
    "        idxSel = idxArr\n",
    "    else:\n",
    "        idxSel = idxArr[:numShallowSamples]\n",
    "    if modelname == \"SVR\":\n",
    "        C = trial.suggest_float(\"C\",1e0,1e4,log=True)\n",
    "        kernel = trial.suggest_categorical(\"kernel\", [\"linear\", \"poly\", \"rbf\", \"sigmoid\"])\n",
    "        if kernel == 'poly':\n",
    "            polyDeg = trial.suggest_int(\"degree\",2,6)\n",
    "        else:\n",
    "            polyDeg = 3\n",
    "        if kernel in ['rbf','poly','sigmoid']:\n",
    "            gamma = trial.suggest_categorical('gamma',['scale', 'auto'])\n",
    "        else:\n",
    "            gamma = 'scale'\n",
    "        if kernel in ['poly','sigmoid']:\n",
    "            coef0 = trial.suggest_float('coef0',0.,0.2)\n",
    "        else:\n",
    "            coef0 = 0.\n",
    "        model = SVR(kernel=kernel, degree=polyDeg, gamma=gamma, coef0=coef0, C=C,verbose=1)\n",
    "        multiRegModel = MultiOutputRegressor(model)\n",
    "        trainLoss, evalLoss = runShallowOpt(multiRegModel, modelname,idxSel)\n",
    "        \n",
    "    elif modelname == \"rfr\":\n",
    "        n_estimators = trial.suggest_int(\"n_estimators\",10,1000)\n",
    "        max_features = trial.suggest_categorical(\"max_features\",[\"sqrt\",\"log2\",None])\n",
    "        max_depth = trial.suggest_int(\"max_depth\",10,100)\n",
    "        model = rfr(n_estimators=n_estimators,max_features=max_features,max_depth=max_depth,verbose=1)\n",
    "        multiRegModel = MultiOutputRegressor(model)\n",
    "        trainLoss, evalLoss = runShallowOpt(multiRegModel, modelname,idxSel)\n",
    "        \n",
    "    elif modelname == \"gradB\":\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\",1e-4,1e0,log=True)\n",
    "        max_leaf_nodes = trial.suggest_int(\"max_leaf_nodes\",1,500)\n",
    "        max_depth = trial.suggest_int(\"max_depth\",10,100)\n",
    "        model = gradB(learning_rate=learning_rate,max_leaf_nodes=max_leaf_nodes,max_depth=max_depth,verbose=1)\n",
    "        multiRegModel = MultiOutputRegressor(model)\n",
    "        trainLoss, evalLoss = runShallowOpt(multiRegModel, modelname,idxSel)\n",
    "        \n",
    "    elif modelname == 'xgboost':\n",
    "        # lambdaVal = trial.suggest_float(\"lambdaVal\",1e-5,1e0,log=True)\n",
    "        # alpha = trial.suggest_float(\"alpha\",1e-5,1e0,log=True)\n",
    "        # learning_rate = trial.suggest_float(\"learning_rate\",1e-5,1e0,log=True)\n",
    "        # max_depth = trial.suggest_int(\"max_depth\",1,500)\n",
    "        # n_estimators = trial.suggest_int(\"n_estimators\",10,10000)\n",
    "        # min_child_weight = trial.suggest_int(\"min_child_weight\",1,500)\n",
    "        paramDict = {\n",
    "            \"lambda\" : trial.suggest_float(\"lambdaVal\",1e-5,1e0,log=True),\n",
    "            \"alpha\" : trial.suggest_float(\"alpha\",1e-5,1e0,log=True),\n",
    "            \"learning_rate\" : trial.suggest_float(\"learning_rate\",1e-5,1e0,log=True),\n",
    "            \"max_depth\" : trial.suggest_int(\"max_depth\",1,20),\n",
    "            \"n_estimators\" : trial.suggest_int(\"n_estimators\",10,10000),\n",
    "            \"min_child_weight\" : trial.suggest_int(\"min_child_weight\",1,500),\n",
    "            'tree_method':'gpu_hist',\n",
    "            'predictor': 'gpu_predictor'\n",
    "            }\n",
    "        \n",
    "        model = xgb.XGBRegressor(**paramDict)\n",
    "        multiRegModel = MultiOutputRegressor(model)\n",
    "        trainLoss, evalLoss = runShallowOpt(multiRegModel, modelname,idxSel)\n",
    "    return evalLoss\n",
    "\n",
    "\n",
    "def litObjective(trial):\n",
    "    \n",
    "    model = LitModel(xTrT[:1000],trial=trial)\n",
    "    trainer= pl.Trainer(\n",
    "        limit_val_batches = 0.2,\n",
    "        logger = tb_logger, max_epochs=epochs, gpus=1,\n",
    "        callbacks=[PyTorchLightningPruningCallback(\n",
    "            trial, monitor=\"val_loss\")])\n",
    "    hyperP = trial.params\n",
    "    trainer.logger.log_hyperparams(hyperP)\n",
    "    trainer.fit(model,train_dataloader=trDl,val_dataloaders=evalDl)\n",
    "    return trainer.callback_metrics[\"val_loss\"].item()\n",
    "    \n",
    "    \n",
    "def objective(trial):\n",
    "\n",
    "    model = makeModel(trial, hpDict=None).to(device)\n",
    "    lr = trial.suggest_float(\"lr\", minLr, maxLr, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\",1e-8,1e-2, log=True)\n",
    "\n",
    "    opti = t.optim.Adam(model.parameters(),lr = lr,\n",
    "                        weight_decay=weight_decay)\n",
    "    evalLossMean = trainNN(model,opti,trDl, evalDl,epochs=epochs,\n",
    "                           trial=trial)\n",
    "    return evalLossMean\n",
    "\n",
    "def trainNN(nnNet,opti,trDl, evalDl,epochs=2, trial=None):\n",
    "\n",
    "    writerCount=0\n",
    "    evalWriterCount=0\n",
    "    trLosses =[]\n",
    "    evalLosses = []\n",
    "    rmsle_eval_Losses = []\n",
    "    print('Trial check: trial is None is ', trial is None)\n",
    "    if 'bestDict' in globals():\n",
    "        L1val = bestDict[\"L1val\"]\n",
    "    if trial is not None:\n",
    "        L1val = trial.suggest_float(\"L1val\",l1min,l1max,log=True)\n",
    "    for e in tqdm(range(epochs)):\n",
    "        epochLossTr = []\n",
    "        epochLossE = []\n",
    "        for i, (x,y) in enumerate(trDl):\n",
    "            nnNet.train()\n",
    "            out = nnNet(x.to(device))\n",
    "            lossTr = criterion(y.to(device), out)\n",
    "            if addL1Reg:\n",
    "                    l2_reg = t.tensor(0.).to(device)\n",
    "                    for nParam, parameter in enumerate(nnNet.parameters()):\n",
    "                        l2_reg += t.linalg.norm(parameter)\n",
    "                    lossTr += L1val * l2_reg\n",
    "            opti.zero_grad()\n",
    "            lossTr.backward()\n",
    "            opti.step()\n",
    "            epochLossTr.append(lossTr.cpu().detach().numpy().item())\n",
    "            if logTB:\n",
    "                writerCount+=1\n",
    "                writerTr.add_scalar(\"lossTr\", lossTr.cpu().detach().numpy().item(),writerCount)\n",
    "            if trial is not None and i >= numBatchesForOptunaTr*batchSize:\n",
    "                break\n",
    "\n",
    "\n",
    "            if i%500==0:\n",
    "                with t.no_grad():\n",
    "                    for iTe,(xTe, yTe) in enumerate(evalDl):\n",
    "                        nnNet.eval()\n",
    "                        outTe = nnNet(xTe.to(device))\n",
    "                        lossTe = criterion(yTe.to(device),outTe)\n",
    "                        if addL1Reg:\n",
    "                            l2_reg = t.tensor(0.).to(device)\n",
    "                            for parameter in nnNet.parameters():\n",
    "                                l2_reg += t.linalg.norm(parameter)\n",
    "                            lossTe += L1val * l2_reg\n",
    "                        epochLossE.append(lossTe.cpu().detach().numpy().item())\n",
    "                        if logTB:\n",
    "                            evalWriterCount +=1\n",
    "                            writerEval.add_scalar(\"lossEval\", lossTe.cpu().detach().numpy().item(),evalWriterCount)\n",
    "                        if trial is not None and iTe >= numBatchesForOptunaTe*batchSize:\n",
    "                            break\n",
    "\n",
    "\n",
    "        trLosses.append(np.mean(epochLossTr))\n",
    "        evalLosses.append(np.mean(epochLossE))\n",
    "        with t.no_grad():\n",
    "            yEPredictedNN = predictAndInvTransform(\n",
    "                     t.Tensor(xET),nnNet.to(t.device('cpu')), deepflag=True\n",
    "                )\n",
    "            nnNet.to(device)\n",
    "            rmsle_eval = RMSLE(yEPredictedNN, yE)\n",
    "            rmsle_eval_Losses.append(rmsle_eval)\n",
    "        if trial is not None:\n",
    "            trial.report(rmsle_eval, e)\n",
    "            if trial.should_prune():\n",
    "                raise opt.exceptions.TrialPruned()\n",
    "        print('\\nEpoch ',e,' mean train Loss ',np.mean(epochLossTr))\n",
    "        print('\\nEpoch ',e,' mean eval Loss ',np.mean(epochLossE))\n",
    "\n",
    "    # plot losses\n",
    "\n",
    "    plt.plot(trLosses, 'k.',label='Train')\n",
    "    plt.plot(evalLosses, 'r.',label='Eval')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Eval')\n",
    "    plt.savefig(f'logs/{dateTimeNow}_MeanEvalLoss_{np.mean(epochLossE):.3f}_Losses.png',dpi=200)\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    return np.mean(rmsle_eval_Losses)\n",
    "\n",
    "\n",
    "def saveBestTrial(study,name):\n",
    "    \n",
    "    trial = study.best_trial\n",
    "    print('\\nBest Study Parameters:')\n",
    "\n",
    "    with open(f'./BestTrialParams{dateTimeNow}_{name}.txt','w+') as f:\n",
    "        for k, v in trial.params.items():\n",
    "            f.write(f\"'{k}':{v}\\n\")\n",
    "            print(f\"'{k}':{v},\")\n",
    "    with open(f'./BestTrialParams{dateTimeNow}_{name}.pkl','wb') as f:\n",
    "        pickle.dump(trial.params, f)\n",
    "\n",
    "\n",
    "def RMSLE(ypred, yreal): #uses natural log\n",
    "    ypred_log = np.log(np.clip(ypred+1,1e-6,1e10))\n",
    "    yreal_log=np.log(np.asarray(yreal)+1)\n",
    "    diffSqr = np.square(ypred_log - yreal_log)\n",
    "    rmsleLoss = np.sqrt(np.mean(diffSqr))\n",
    "    return rmsleLoss\n",
    "\n",
    "def predictAndInvTransform(x,model, deepflag=False):\n",
    "    if deepflag:\n",
    "        yPred = model(x)        \n",
    "    else:\n",
    "        yPred = model.predict(x)    \n",
    "    yPredInv = ssTarget.inverse_transform(yPred)\n",
    "    if logRedistr:\n",
    "        yPredInv = np.exp(yPredInv)-1\n",
    "    if doBoxCox:\n",
    "        yPredInv = powTrans.inverse_transform(yPredInv)\n",
    "    if np.isnan(yPredInv).sum()>0:\n",
    "        yPredInv = np.nan_to_num(yPredInv,copy=True)\n",
    "    return yPredInv\n",
    "\n",
    "def runShallow(model, doFit=True):\n",
    "    if doFit:\n",
    "        with parallel_backend('threading', n_jobs=-1):\n",
    "            model.fit(xTrT, yTrT)\n",
    "    #keep out of with statement to avoid kernel crash\n",
    "    \n",
    "    yTrPredInvTrans = predictAndInvTransform(xTrT, model)\n",
    "    yEPredInvTrans = predictAndInvTransform(xET, model)\n",
    "\n",
    "    mseLoss = mse(yEPredInvTrans, yE)\n",
    "    rmsleLossTrain = RMSLE(yTrPredInvTrans, yTr)\n",
    "    rmsleLossEval = RMSLE(yEPredInvTrans, yE)\n",
    "\n",
    "    predSub = predictAndInvTransform(teDT,model)\n",
    "\n",
    "    return model, mseLoss,  predSub, rmsleLossEval, rmsleLossTrain\n",
    "\n",
    "def saveSubmission(data,name, returnDf = False):\n",
    "    dfSubmission = pd.DataFrame(data=data,\n",
    "                                index=np.arange(0,len(data),1))\n",
    "    dfSubmission.reset_index(inplace=True,drop=False)\n",
    "    dfSubmission.columns = [idCol,*targetCols]\n",
    "    dfSubmission[idCol] = testDataRaw[idCol]\n",
    "    # dfSubmission.rename({'index':'id'},inplace=True)\n",
    "    dfSubmission.to_csv(f'logs/{dateTimeNow}_{name}_Submission.csv',index=False)\n",
    "    if returnDf:\n",
    "        return dfSubmission\n",
    "\n",
    "\n",
    "\n",
    "def addPastDataFeatures(df,pastPoints,cols):\n",
    "    \"\"\"\n",
    "    Pass cols as list even if single\n",
    "    pastPoints is how far into the past to go\n",
    "    \"\"\"\n",
    "    if pastPoints>2:\n",
    "        for p in range(1,pastPoints):\n",
    "            for col in cols:\n",
    "                oldColName = col\n",
    "                newColName = f\"{col}-{p}\"\n",
    "                df.at[:p-1,newColName] = df.at[0,oldColName]\n",
    "                for i in range(p,len(df)):\n",
    "                    df.at[i,newColName] = df.at[i-p,oldColName]\n",
    "    return df\n",
    "\n",
    "\n",
    "def runAll(trD,teD,trTarget,trainingCols,targetCols):\n",
    "\n",
    "    return modelsEvalScores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d3a10d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User toggles\n",
    "\n",
    "\n",
    "#Datadir\n",
    "mainDir = r\"E:\\KaggleData\\Tabular Playground Series - Jul 2021\"\n",
    "\n",
    "\"\"\"\n",
    "uses mean column-wise root mean squared logarithmic error\n",
    "\"\"\"\n",
    "\n",
    "#Hyperparameters and toggles\n",
    "loopVarName = \"pastPoints\"\n",
    "forLoop = range(1,100,5)\n",
    "finalEvalDictName = \"finalEvalScores_30PastFeatures_PCA\"\n",
    "retrainModels = True\n",
    "\n",
    "splitRatio = 0.65 #for train eval split\n",
    "epochs = 500\n",
    "lr = 6e-6\n",
    "batchSize = 1024\n",
    "addL1Reg = True\n",
    "L1val = 0.004\n",
    "weight_decay = 1e-4\n",
    "doLearningCurve = False\n",
    "\n",
    "logTB = True\n",
    "logTB_lightining = True\n",
    "\n",
    "doShallows =1\n",
    "doPYNN = 0\n",
    "doLightning = 0\n",
    "tuneModel = 0\n",
    "\n",
    "optimizeWeightedSum = False\n",
    "doOptuna = 0 #applies to all methods above\n",
    "\n",
    "#optuna Params\n",
    "possibleActiFuncs = [\"ReLU\",\"LeakyReLU\",\"Tanh\"] #,\"Sigmoid\",\"LeakyReLU\",\"Tanh\"\n",
    "minLayers = 1\n",
    "maxLayers = 10\n",
    "minNeurons = 20\n",
    "maxNeurons = 1000 #TODO try powers of 2 with int suggest\n",
    "minDropOut = 0.3\n",
    "maxDropOut = 0.7\n",
    "l1min = 1e-7 #not used for lightning\n",
    "l1max = 1e-2\n",
    "minWD = 1e-6\n",
    "maxWD = 5e-3 #used for lightning\n",
    "minLr = 1e-7\n",
    "maxLr = 1e-2\n",
    "maxTrials = 120\n",
    "maxTime = 1*60*60\n",
    "numBatchesForOptunaTr = 30\n",
    "numBatchesForOptunaTe = 20\n",
    "\n",
    "#optuna shallow params\n",
    "possibleShallows = [\"rfr\"]#\"rfr\",\"SVR\",\"gradB\",\"xgboost\"\n",
    "numShallowSamples = 50000\n",
    "\n",
    "#Toggles for data augmentation overview\n",
    "doPCA = False #looks to be unhelpful\n",
    "doBoxCox = 1 # works quite well but requires to be fit to Training data\n",
    "logRedistr = 0 # might not be the best\n",
    "duplicateUnderrepData = True #Adds copies of data points to compensate deviation from normal distr\n",
    "dupliFac = 3 #how many times the data should be appended\n",
    "\n",
    "#create extra features from previous data points\n",
    "pastPoints = 2 # this number -1 is number of new features per column\n",
    "redoPastDataAdding = True\n",
    "\n",
    "plotPCA = False\n",
    "checkHist = 1 #Target data looks like double normal distribution\n",
    "plotCorreclations = 0\n",
    "plotTargetsOverTime = 0\n",
    "printDataStats = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b609464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up data files and create logging dirs\n",
    "\n",
    "\n",
    "with open(f'{mainDir}/BestTrialParams20210710-180700.pkl','rb') as f:\n",
    "            bestDict = pickle.load(f)\n",
    "    \n",
    "    \n",
    "os.chdir(mainDir)\n",
    "dateTimeNow =  datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "if logTB and doPYNN:\n",
    "    writerTr = SummaryWriter(\"logs/\"+dateTimeNow+\"TrainLosses\")\n",
    "    writerEval = SummaryWriter(\"logs/\"+dateTimeNow+\"EvalLosses\")\n",
    "if logTB_lightining and doLightning:\n",
    "    tb_logger = pl.loggers.TensorBoardLogger('lightning_logs/')\n",
    "\n",
    "trainDataRaw = pd.read_csv(\"train.csv\")\n",
    "testDataRaw = pd.read_csv(\"test.csv\")\n",
    "\n",
    "targetCols = [\"target_carbon_monoxide\",\"target_benzene\",\"target_nitrogen_oxides\"]\n",
    "idCol = \"date_time\"\n",
    "trainingCols = list(trainDataRaw.columns)\n",
    "for col in targetCols.copy():\n",
    "    trainingCols.remove(col)\n",
    "trainingCols.remove(idCol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff2d64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to test different options\n",
    "\n",
    "\n",
    "resultDicts=[]\n",
    "resultsDf = pd.DataFrame()\n",
    "for loopIdx,loopVar in enumerate(forLoop):\n",
    "    globals()[loopVarName] = loopVar\n",
    "    finalEvalDictName = f\"{loopVarName}_{loopVar}.txt\"\n",
    "    \n",
    "\n",
    "    trD = trainDataRaw.drop([*targetCols,idCol],axis=1).copy()\n",
    "    teD = testDataRaw.copy().drop([idCol],axis=1)\n",
    "    trTarget = trainDataRaw[targetCols].copy()\n",
    "\n",
    "    if logRedistr:\n",
    "        trTargetBefore = np.round(trTarget.copy(),10)\n",
    "        trTarget = np.round(np.log1p(trTarget),10)\n",
    "        trTargetRecovered = np.round(np.exp(trTarget)-1,10)\n",
    "        print('Recovery difference: ', np.sum((trTargetRecovered-trTargetBefore)))\n",
    "\n",
    "\n",
    "    if duplicateUnderrepData:\n",
    "        for i in range(dupliFac):\n",
    "            extraData = trTarget[trTarget[\"target_benzene\"]>=0.2]\n",
    "            extraData = extraData.append(extraData)\n",
    "        trTarget = trTarget.append(extraData)\n",
    "\n",
    "\n",
    "    allCols = list(trD.keys())\n",
    "    if redoPastDataAdding:\n",
    "        print('Redoing past points with ',pastPoints,' points')\n",
    "        trD = addPastDataFeatures(trD, pastPoints, allCols)\n",
    "        with open('trainDataAug.pkl','wb') as f:\n",
    "            pickle.dump(trD,f) \n",
    "        teD = addPastDataFeatures(teD, pastPoints, allCols)\n",
    "        with open('testDataAug.pkl','wb') as f:\n",
    "            pickle.dump(teD,f) \n",
    "    else:\n",
    "        with open('trainDataAug.pkl','rb') as f:\n",
    "            trD=pickle.load(f) \n",
    "        with open('testDataAug.pkl','rb') as f:\n",
    "            teD=pickle.load(f) \n",
    "\n",
    "    #trD.to_html('trD.html')\n",
    "            \n",
    "\n",
    "    if doPCA:\n",
    "        pca = PCA(n_components=10).fit(trD)\n",
    "        trD = pca.transform(trD)\n",
    "        teD = pca.transform(teD)\n",
    "        print(trD.shape,teD.shape)\n",
    "        if plotPCA:\n",
    "            pcaPlot = PCA(n_components=3).fit(trainDataRaw.drop([*targetCols,idCol],axis=1), y=trTarget)\n",
    "            xPCAplot = pcaPlot.transform(trainDataRaw.drop([*targetCols,idCol],axis=1))\n",
    "            yPCAplot = trTarget.copy()\n",
    "\n",
    "            #%matplotlib qt\n",
    "\n",
    "            fig = plt.figure()\n",
    "            ax = fig.add_subplot(projection='3d')\n",
    "            numSamples = 1000\n",
    "            idxArr = np.arange(len(xPCAplot))\n",
    "            np.random.shuffle(idxArr)\n",
    "            idxSel = idxArr[:numSamples]\n",
    "            ax.scatter(xPCAplot[idxSel,0], xPCAplot[idxSel,1], xPCAplot[idxSel,2], c = yPCAplot[idxSel])\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "    #Random split should be ok, because time windows were added as features\n",
    "\n",
    "    idx = np.arange(0,len(trD))\n",
    "    np.random.shuffle(idx)\n",
    "    trainIdx = idx[:int(len(trD)*splitRatio)]\n",
    "    testIdx = idx[int(len(trD)*splitRatio):]\n",
    "    xTr =np.asarray(trD)[trainIdx]\n",
    "    xE= np.asarray(trD)[testIdx]\n",
    "    yTr = np.asarray(trTarget)[trainIdx]\n",
    "    yE = np.asarray(trTarget)[testIdx]\n",
    "\n",
    "\n",
    "    xTrT = xTr.copy()\n",
    "    xET = xE.copy()\n",
    "    teDT = teD.copy()\n",
    "\n",
    "    yTrT = yTr.copy()\n",
    "    yET = yE.copy()\n",
    "\n",
    "    if doBoxCox:   \n",
    "        yTrTBefore = yTrT.copy()\n",
    "        powTrans = PowerTransformer(method='box-cox',standardize=False)\n",
    "        powTrans.fit(yTrT)\n",
    "        yTrT = powTrans.transform(yTrT)\n",
    "        yTrTRecovered = powTrans.inverse_transform(yTrT.copy())\n",
    "        print('Recovery difference: ', np.sum((yTrTRecovered-yTrTBefore)))\n",
    "\n",
    "        yET = powTrans.transform(yET)\n",
    "        \n",
    "\n",
    "\n",
    "    if checkHist:\n",
    "        fig, axs = plt.subplots(len(trTarget.columns),1,dpi=300,squeeze=False)\n",
    "        for iC, c in enumerate(trTarget.columns):\n",
    "            skew = trTarget[c].skew()\n",
    "            axs[iC,0].hist(trTarget[c],bins=200)\n",
    "            axs[iC,0].set_xlabel(c)\n",
    "            axs[iC,0].set_ylabel('Frequency')\n",
    "            axs[iC,0].set_title(rf\"Skew of {c} is {skew:.4f}\")\n",
    "        fig.savefig(f'./TargetData_Histogram.png',dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if plotCorreclations:\n",
    "        corrs = trainDataRaw.drop(idCol,axis=1).corr()\n",
    "        corrPlotThreshold = 1 # to check for weak correlations, cont11 and 12 correlate highly\n",
    "        sb.heatmap(corrs[(corrs < corrPlotThreshold)&(corrs > -corrPlotThreshold)])\n",
    "        plt.savefig('./AllCorrelations.png',dpi=300)\n",
    "        plt.close()\n",
    "        plt.plot(corrs.keys().drop(targetCols),corrs[targetCols].drop(targetCols),'k.')\n",
    "        plt.ylabel('Correlation with target')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.savefig('./CorrelationsWithTarget.png',dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    if plotTargetsOverTime:\n",
    "        plotDf = trainDataRaw[[idCol,*targetCols]].copy()\n",
    "        for c in targetCols:\n",
    "            plotDf.loc[:,c]/=plotDf[c].max()\n",
    "            plotDf.loc[:,c] = plotDf[c].rolling(80).mean()\n",
    "        plotDf.plot(x=idCol, y=targetCols,rot=45)\n",
    "        plt.savefig('./RollingTargetsOverTime.png',dpi=300)\n",
    "\n",
    "\n",
    "\n",
    "    # Normalise\n",
    "    ssTr = ss().fit(xTrT)\n",
    "\n",
    "    xTrT = ssTr.transform(xTrT)\n",
    "    xET = ssTr.transform(xET)\n",
    "    teDT = ssTr.transform(teD)\n",
    "\n",
    "    ssTarget = ss().fit(yTrT)\n",
    "    yTrT = ssTarget.transform(yTrT)\n",
    "    yET = ssTarget.transform(yET)\n",
    "\n",
    "    #Check stats\n",
    "    if printDataStats:\n",
    "        print('\\n raw train data stats:')\n",
    "        trainDataRaw.drop(idCol,axis=1).info(verbose=1)\n",
    "        print(trainDataRaw.drop(idCol,axis=1).describe())\n",
    "        tempTrainDf = pd.DataFrame(data=xTrT,columns=trD.columns,index=range(len(xTrT)))\n",
    "        tempTrainDf.info(verbose=1)\n",
    "        print(tempTrainDf.describe())\n",
    "\n",
    "    #make Dataloaders\n",
    "    dSetTr = TensorDataset(t.Tensor(xTrT), t.Tensor(yTrT))\n",
    "    dSetE = TensorDataset(t.Tensor(xET), t.Tensor(yET))\n",
    "\n",
    "    dSetTr2 = dset(xTrT, yTrT)\n",
    "    dSetE2 = dset(xET,yET)\n",
    "    trDl = dl(dSetTr,batch_size=batchSize,shuffle=False)\n",
    "    evalDl = dl(dSetE,batch_size=batchSize,shuffle=False)\n",
    "\n",
    "    modelsEvalScores = {} #init results dict\n",
    "    # Shallow tests\n",
    "\n",
    "\n",
    "    def weightedSum(weights):\n",
    "        \"\"\"\n",
    "        Takes in weight arrays\n",
    "        return loss\n",
    "        \"\"\"\n",
    "        yTrPred = (weights[0]*predictAndInvTransform(xTrT,multiRegXG)+\n",
    "            weights[1]*predictAndInvTransform(xTrT,ranSVR)+\n",
    "            weights[2]*predictAndInvTransform(xTrT,ranForest))\n",
    "\n",
    "        yEPred = (weights[0]*predictAndInvTransform(xET,multiRegXG)+\n",
    "            weights[1]*predictAndInvTransform(xET,ranSVR)+\n",
    "            weights[2]*predictAndInvTransform(xET,ranForest))\n",
    "\n",
    "        loss = RMSLE(yTr,yTrPred) + RMSLE(yE,yEPred)\n",
    "        return loss\n",
    "\n",
    "    if doShallows:\n",
    "\n",
    "        if doOptuna:\n",
    "            studyShallow = opt.create_study(direction=\"minimize\")\n",
    "            studyShallow.optimize(shallowObjective, maxTrials, timeout=maxTime)\n",
    "            shallowTrial = studyShallow.best_trial\n",
    "            print(shallowTrial)\n",
    "            saveBestTrial(studyShallow,'Shallow')        \n",
    "            opt.visualization.plot_param_importances(studyShallow)\n",
    "        else:\n",
    "            \n",
    "            \n",
    "\n",
    "            if retrainModels:\n",
    "                with open(rf'{mainDir}/BestTrialParams20210710-190103_Shallow.pkl','rb') as f:\n",
    "                    paramDictXGBoost=pickle.load(f)\n",
    "                paramDictXGBoost ['tree_method']='gpu_hist'\n",
    "                paramDictXGBoost ['predictor']='gpu_predictor' \n",
    "                if \"lambdaVal\" in paramDictXGBoost.keys():\n",
    "                    paramDictXGBoost[\"lambda\"] = paramDictXGBoost[\"lambdaVal\"]\n",
    "                    del paramDictXGBoost[\"lambdaVal\"]\n",
    "                if \"modelname\" in paramDictXGBoost.keys():\n",
    "                    del paramDictXGBoost[\"modelname\"]\n",
    "                #BestTrialParams20210704-145220_Shallow.pkl\n",
    "                multiRegXG = MultiOutputRegressor(xgb.XGBRegressor(**paramDictXGBoost))\n",
    "\n",
    "                print('Fitting XGBoost now')\n",
    "                multiRegXG, mseLoss, predSub, rmsleLoss, rmsleLossTrain = runShallow(multiRegXG)\n",
    "                print('XGBRegressor MSE: ',mseLoss)\n",
    "                print('XGBRegressor RMSLE: ', rmsleLoss, ' Train: ',rmsleLossTrain)\n",
    "                pickleSave(f\"{mainDir}/XGBRegressor_{dateTimeNow}.pkl\",multiRegXG)\n",
    "            else:\n",
    "                multiRegXG = pickleLoad('XGBRegressor_20210714-182211.pkl')\n",
    "                multiRegXG, mseLoss, predSub, rmsleLoss, rmsleLossTrain = runShallow(multiRegXG,doFit=False)\n",
    "                predSub = predictAndInvTransform(teDT,multiRegXG)\n",
    "            xgPrediction = saveSubmission(predSub, 'Shallow_XGBoost', True)\n",
    "            \n",
    "            modelsEvalScores[\"multiRegXG\"]=rmsleLoss            \n",
    "            modelsEvalScores[\"multiRegXGTrain\"]=rmsleLossTrain\n",
    "\n",
    "            if retrainModels:                \n",
    "                bestSVR = {\n",
    "                    'modelname': 'SVR',\n",
    "                    'C': 35.542238529147916,\n",
    "                    'kernel': 'poly',\n",
    "                    'degree': 2,\n",
    "                        'gamma': 'scale',\n",
    "                        'coef0': 0.1829941183576717}\n",
    "                del bestSVR[\"modelname\"]\n",
    "                svrMulti = MultiOutputRegressor(SVR(**bestSVR))\n",
    "                ranSVR, mseLoss, predSub, rmsleLoss, rmsleLossTrain = runShallow(svrMulti)\n",
    "                print('SVR MSE: ',mseLoss)\n",
    "                print('SVR RMSLE: ', rmsleLoss, ' Train: ',rmsleLossTrain)\n",
    "                pickleSave(f\"{mainDir}/ranSVR_{dateTimeNow}.pkl\",ranSVR)\n",
    "            else:\n",
    "                ranSVR = pickleLoad('ranSVR_20210714-182211.pkl')\n",
    "                ranSVR, mseLoss, predSub, rmsleLoss, rmsleLossTrain = runShallow(ranSVR,False)\n",
    "                predSub = predictAndInvTransform(teDT,ranSVR)\n",
    "            SVRPrediction = saveSubmission(predSub, 'Shallow_SVR', True)\n",
    "            modelsEvalScores[\"ranSVR\"]=rmsleLoss            \n",
    "            modelsEvalScores[\"ranSVRTrain\"]=rmsleLossTrain\n",
    "\n",
    "            if retrainModels:\n",
    "                    \n",
    "                with open(rf'{mainDir}/BestTrialParams20210711-085005_Shallow.pkl','rb') as f:\n",
    "                    bestForestDict=pickle.load(f)\n",
    "                # bestForestDict = {\n",
    "                # 'modelname':rfr,\n",
    "                # 'n_estimators':978,\n",
    "                # 'max_features':'log2',\n",
    "                # 'max_depth':81\n",
    "                # } \n",
    "                del bestForestDict[\"modelname\"]\n",
    "                multiRegForest = MultiOutputRegressor(\n",
    "                    rfr(**bestForestDict))\n",
    "\n",
    "                ranForest, mseLoss, predSub, rmsleLoss, rmsleLossTrain = runShallow(multiRegForest)\n",
    "                print('Forest MSE: ',mseLoss)\n",
    "                print('Forest RMSLE: ', rmsleLoss, ' Train: ',rmsleLossTrain)\n",
    "                pickleSave(f\"{mainDir}/ranForest_{dateTimeNow}.pkl\",ranForest)\n",
    "            else:\n",
    "                ranForest = pickleLoad('ranForest_20210714-182211.pkl')\n",
    "                ranForest, mseLoss, predSub, rmsleLoss, rmsleLossTrain = runShallow(ranForest,False)\n",
    "                predSub = predictAndInvTransform(teDT,ranForest)\n",
    "            forestPrediction = saveSubmission(predSub, 'Shallow_Forest', True)        \n",
    "            modelsEvalScores[\"ranForest\"]=rmsleLoss\n",
    "            modelsEvalScores[\"ranForestTrain\"]=rmsleLossTrain\n",
    "\n",
    "            if optimizeWeightedSum:\n",
    "                weightedSumOfPreds = weightedSum(np.array([0.04917891, 0.10612977, 0.87730408]))\n",
    "                xLims =np.array([[0,1],[0,1],[0,1]])\n",
    "                boundsSci = (xLims[0,:],xLims[1,:],xLims[2,:])\n",
    "\n",
    "                objectives = [weightedSum]\n",
    "                \n",
    "                algo = NSGA2(100, n_offsprings=50)\n",
    "                funcProb = FunctionalProblem(\n",
    "                            3,objectives,xl=xLims[:,0],xu=xLims[:,1])\n",
    "                \n",
    "                results = minimize(\n",
    "                    funcProb,algo,get_termination(\"n_gen\", 200),\n",
    "                    save_history=True,verbose=True,display=MyDisplay())\n",
    "                print(\"NSGA2: \",results.X, results.F, results.CV)\n",
    "                \n",
    "                weightedSumOfPreds = weightedSum(results.X)\n",
    "                weightedSumOfPreds = (\n",
    "                    results.X[0]*forestPrediction[targetCols].to_numpy( dtype=np.float32)+\n",
    "                    results.X[1]*SVRPrediction[targetCols].to_numpy( dtype=np.float32)+\n",
    "                    results.X[2]*xgPrediction[targetCols].to_numpy( dtype=np.float32)\n",
    "                )\n",
    "                pickleSave(f\"{mainDir}/weightsSumming_{dateTimeNow}.pkl\",results)\n",
    "                weightedSubmission = saveSubmission(weightedSumOfPreds, 'weightedSumOfPreds', True)\n",
    "                modelsEvalScores[\"weightedAvg\"]=results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # nn approach\n",
    "    device = t.device('cuda') if t.cuda.is_available() else t.device('cpu')\n",
    "    writerCount = 0\n",
    "    evalWriterCount = 0\n",
    "\n",
    "            \n",
    "    if doPYNN:\n",
    "        \n",
    "\n",
    "        if doOptuna:\n",
    "            criterion = nn.MSELoss()\n",
    "            study = opt.create_study(direction=\"minimize\")\n",
    "            study.optimize(objective, n_trials=maxTrials, timeout=maxTime)\n",
    "            trial = study.best_trial\n",
    "            print('\\nBest Study Parameters:')\n",
    "\n",
    "            with open(f'./BestTrialParams{dateTimeNow}.txt','w+') as f:\n",
    "                for k, v in trial.params.items():\n",
    "                    f.write(f\"'{k}':{v}\\n\")\n",
    "                    print(f\"'{k}':{v},\")\n",
    "            with open(f'./BestTrialParams{dateTimeNow}.pkl','wb') as f:\n",
    "                pickle.dump(trial.params, f)\n",
    "            opt.visualization.plot_param_importances(study)\n",
    "        elif doLearningCurve:\n",
    "            indsTr =np.arange(len(dSetTr))\n",
    "            np.random.shuffle(indsTr)\n",
    "            subTrDl = dl(Subset(dSetTr,indsTr[:50000]),batch_size=batchSize,shuffle=True)\n",
    "\n",
    "            nnNet = makeModel(bestDict).to(device)\n",
    "            opti = t.optim.Adam(nnNet.parameters(), lr = bestDict[\"lr\"])\n",
    "            criterion = nn.MSELoss()\n",
    "\n",
    "            evalLossFromTrain = trainNN(nnNet,opti,subTrDl, evalDl, epochs=10)\n",
    "            print('Final Loss val ', evalLossFromTrain)\n",
    "\n",
    "        else:\n",
    "            nnNet = makeModel(hpDict=bestDict).to(device)\n",
    "            opti = t.optim.Adam(\n",
    "                nnNet.parameters(), lr = bestDict[\"lr\"],\n",
    "                weight_decay=1e-3)\n",
    "            criterion = nn.MSELoss()\n",
    "\n",
    "            evalLossFromTrain = trainNN(nnNet,opti,trDl, evalDl,epochs = epochs)\n",
    "            print('Final Loss val ', evalLossFromTrain)\n",
    "\n",
    "            nnNet.eval()\n",
    "            with t.no_grad():\n",
    "                yEPredictedNN = predictAndInvTransform(\n",
    "                        t.Tensor(xET),nnNet.to(t.device('cpu')), deepflag=True\n",
    "                    )\n",
    "                nnFinalEvalLoss = RMSLE(yEPredictedNN, yE)\n",
    "\n",
    "                yTrPredictedNN = predictAndInvTransform(\n",
    "                        t.Tensor(xTrT),nnNet.to(t.device('cpu')), deepflag=True\n",
    "                    )\n",
    "                nnFinalTrainLoss = RMSLE(yTrPredictedNN, yTr)\n",
    "\n",
    "                yPredNN = predictAndInvTransform(\n",
    "                    t.Tensor(teDT),nnNet.to(t.device('cpu')), deepflag=True)\n",
    "                saveSubmission(yPredNN, 'DeepNN')\n",
    "                print('\\nNN model final RMSLE Loss:')\n",
    "                print(f\"Train: {nnFinalTrainLoss}, Eval: {nnFinalEvalLoss}\")\n",
    "            modelsEvalScores[\"NN\"]=nnFinalEvalLoss\n",
    "            modelsEvalScores[\"NNTrain\"]=nnFinalTrainLoss\n",
    "        \n",
    "\n",
    "    ## nn with LightningModule\n",
    "    if doLightning:\n",
    "        \n",
    "        if doOptuna:\n",
    "            \n",
    "            bestDict = None\n",
    "            study = opt.create_study(direction=\"minimize\", pruner=opt.pruners.MedianPruner())\n",
    "            study.optimize(litObjective,n_trials=maxTrials, timeout=maxTime)\n",
    "            saveBestTrial(study, 'Lightning')\n",
    "            #Visualize parameter importances.\n",
    "            opt.visualization.plot_param_importances(study)\n",
    "        else:\n",
    "            with open('BestTrialParams20210704-125835_Lightning.pkl','rb') as f:\n",
    "                bestDict = pickle.load(f)\n",
    "            \n",
    "            trainer = pl.Trainer(\n",
    "                gpus=1,max_epochs=epochs,stochastic_weight_avg=True, logger=tb_logger)\n",
    "            model1 = LitModel(t.Tensor(xTrT[:50]).float())\n",
    "            if tuneModel:\n",
    "                lr_finder = trainer.tuner.lr_find(model1,trDl,evalDl)\n",
    "                fig = lr_finder.plot(suggest=True)\n",
    "                fig.savefig('LR_finder.png')\n",
    "                new_lr = lr_finder.suggestion()\n",
    "                # trainer.tune(model1,trDl)\n",
    "            else:\n",
    "                trainer.fit(model1, trDl, evalDl)\n",
    "                with t.no_grad():\n",
    "                    yEPredictedLit = predictAndInvTransform(\n",
    "                        t.Tensor(xET),model1, deepflag=True\n",
    "                    )\n",
    "                    litFinalEvalLoss = RMSLE(yEPredictedLit, yE)\n",
    "\n",
    "                    yTrPredictedLit = predictAndInvTransform(\n",
    "                        t.Tensor(xTrT),model1, deepflag=True\n",
    "                    )\n",
    "                    litFinalTrainLoss = RMSLE(yTrPredictedLit, yTr)\n",
    "\n",
    "                    print('\\nLighting model final RMSLE Loss:')\n",
    "                    print(f\"Train: {litFinalTrainLoss}, Eval: {litFinalEvalLoss}\")\n",
    "                    yPredLit = predictAndInvTransform(\n",
    "                        t.Tensor(teDT),model1, deepflag=True)\n",
    "                    saveSubmission(yPredLit, 'DeepLit')\n",
    "                    modelsEvalScores[\"NNLightning\"]=litFinalEvalLoss\n",
    "                    modelsEvalScores[\"NNTrain\"]=litFinalTrainLoss\n",
    "    modelsEvalScores[loopVarName] = loopVar\n",
    "    tempDf = pd.DataFrame(modelsEvalScores,index=[loopIdx])\n",
    "    resultsDf=resultsDf.append(tempDf)\n",
    "    if \"modelsEvalScores\" in locals():\n",
    "        with open(f\"{finalEvalDictName}.txt\",\"w+\") as f:\n",
    "            for k in modelsEvalScores.keys():\n",
    "                f.write(f\"{k}: {modelsEvalScores[k]},\\n\")\n",
    "                \n",
    "    res = modelsEvalScores\n",
    "    resultDicts.append([loopVar,res])\n",
    "    pickleSave(f'{loopVarName}_resultDicts.pkl',resultDicts)    \n",
    "    pickleSave(f'{loopVarName}_resultsDf.pkl',resultsDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a66255",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32412c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'RMSLE')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot results from loops for loopVar \"pastPoints\"\n",
    "\n",
    "loopVarName = \"pastPoints\"\n",
    "\n",
    "resultsDf = pickleLoad(f'{loopVarName}_resultsDf.pkl')\n",
    "\n",
    "resultsDf.plot(x=loopVarName,y=resultsDf.keys().to_list().remove(loopVarName)).legend(bbox_to_anchor=(1,1))\n",
    "plt.ylabel(\"RMSLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7883e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03084096",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlcv4_jupyter",
   "language": "python",
   "name": "mlcv4_jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
